// Generated by CoffeeScript 1.12.7
var bestChoice, expandPhrase, expandSynonym, expandToken, fixPunctuation, flatten, fs, generate, getPhraseDependencies, inspect, nearley, parse, parser_grammar, randomChoice, ref, sortBy,
  indexOf = [].indexOf || function(item) { for (var i = 0, l = this.length; i < l; i++) { if (i in this && this[i] === item) return i; } return -1; };

nearley = require('nearley');

fs = require('fs');

parser_grammar = require('./grammar');

ref = require('./helpers'), inspect = ref.inspect, sortBy = ref.sortBy, flatten = ref.flatten, randomChoice = ref.randomChoice, fixPunctuation = ref.fixPunctuation;

exports.parse = parse = function(grammar_string) {
  var grammar, parsed, parser, phrase_key, phrases, ref1;
  if (grammar_string.endsWith('.nlg')) {
    grammar_string = fs.readFileSync(grammar_string, 'utf8');
  }
  grammar_string = grammar_string.trim();
  parser = new nearley.Parser(parser_grammar.ParserRules, parser_grammar.ParserStart);
  parser.feed(grammar_string);
  parsed = parser.results[0];
  grammar = {
    phrases: {},
    synonyms: {}
  };
  parsed.forEach(function(block) {
    if (block.phrase) {
      return grammar.phrases[block.phrase] = block;
    } else if (block.phrase === '') {
      return grammar.phrases.root = block;
    } else if (block.synonym) {
      return grammar.synonyms[block.synonym] = block;
    }
  });
  ref1 = grammar.phrases;
  for (phrase_key in ref1) {
    phrases = ref1[phrase_key];
    phrases.lines.forEach(function(phrase, pi) {
      return phrase.dependencies = getPhraseDependencies(phrase, grammar);
    });
  }
  return grammar;
};

getPhraseDependencies = function(phrase, grammar) {
  var phrase_phrases, phrase_values, sub_dependencies;
  phrase_values = phrase.filter(function(token) {
    return token.value != null;
  }).map(function(token) {
    return token.value;
  });
  phrase_phrases = phrase.filter(function(token) {
    return token.phrase != null;
  }).map(function(token) {
    return token.phrase;
  });
  sub_dependencies = flatten(flatten(phrase_phrases.map(function(phrase_key) {
    return grammar.phrases[phrase_key].lines.map(function(phrase, pi) {
      return getPhraseDependencies(phrase, grammar);
    });
  })));
  return phrase_values.concat(sub_dependencies);
};

bestChoice = function(phrases, values) {
  var available_values, best_count, best_phrases, countDependencies, filtered_phrases, value_counts;
  available_values = Object.keys(values);
  filtered_phrases = phrases.filter(function(phrase) {
    var dependency, i, len, ref1;
    ref1 = phrase.dependencies;
    for (i = 0, len = ref1.length; i < len; i++) {
      dependency = ref1[i];
      if (indexOf.call(available_values, dependency) < 0) {
        return false;
      }
    }
    return true;
  });
  countDependencies = function(phrase) {
    return phrase.dependencies.length;
  };
  value_counts = filtered_phrases.map(countDependencies);
  best_phrases = sortBy(filtered_phrases, countDependencies);
  best_count = countDependencies(best_phrases[0]);
  best_phrases = best_phrases.filter(function(phrase) {
    return countDependencies(phrase) === best_count;
  });
  return randomChoice(best_phrases);
};

expandToken = function(token, grammar, context) {
  var expanded, expander, formatted, formatter, group_expanded, group_token, i, item, joiner, len, phrase, phrase_expanded, phrase_token, ref1, secondary, synonym, synonym_token, tokenExpander, value, value_token, word_token;
  expanded = [];
  if (word_token = token.word) {
    expanded.push(word_token);
  } else if (group_token = token.group) {
    group_expanded = token.group.map(function(token) {
      return expandToken(token, grammar, context);
    });
    expanded.push(group_expanded.join(' '));
  } else if (phrase_token = token.phrase) {
    phrase = grammar.phrases[phrase_token];
    phrase_expanded = expandPhrase(phrase, grammar, context);
    expanded.push(phrase_expanded);
  } else if (synonym_token = token.synonym) {
    synonym = grammar.synonyms[synonym_token];
    expanded.push(expandSynonym(synonym, grammar, context));
  } else if (value_token = token.value) {
    value = context.values[value_token];
    if (expander = token.expander) {
      tokenExpander = function(item) {
        var item_context;
        item_context = Object.assign({}, context, {
          values: item
        });
        return expandToken({
          phrase: expander
        }, grammar, item_context);
      };
      if (Array.isArray(value)) {
        value = value.map(tokenExpander);
      } else {
        value = tokenExpander(value);
      }
    }
    if (Array.isArray(value) && (joiner = token.joiner)) {
      if (value.length === 1) {
        expanded.push(value[0]);
        return expanded;
      }
      ref1 = value.slice(0, -2);
      for (i = 0, len = ref1.length; i < len; i++) {
        item = ref1[i];
        expanded.push(item);
        expanded.push(expandToken(joiner, grammar, context));
      }
      if (secondary = token.secondary) {
        expanded.push(value.slice(-2)[0]);
        if (token.oxford) {
          expanded.push(expandToken(joiner, grammar, context));
        }
        expanded.push(expandToken(secondary, grammar, context));
      } else {
        expanded.push(value.slice(-2)[0]);
        expanded.push(expandToken(joiner, grammar, context));
      }
      expanded.push(value.slice(-1)[0]);
    } else if (formatter = token.formatter) {
      formatted = context.formatters[formatter](value);
      expanded.push(formatted);
    } else {
      expanded.push(value);
    }
  }
  return expanded;
};

expandPhrase = function(phrase, grammar, context) {
  var expanded, i, len, line, token;
  expanded = [];
  line = bestChoice(phrase.lines, context.values);
  for (i = 0, len = line.length; i < len; i++) {
    token = line[i];
    expanded = expanded.concat(expandToken(token, grammar, context));
  }
  return expanded.join(' ');
};

expandSynonym = function(synonym, grammar, context) {
  var expanded, i, len, line, token;
  expanded = [];
  line = randomChoice(synonym.lines);
  for (i = 0, len = line.length; i < len; i++) {
    token = line[i];
    expanded = expanded.concat(expandToken(token, grammar, context));
  }
  return expanded.join(' ');
};

exports.generate = generate = function(grammar, context, root_node) {
  if (root_node == null) {
    root_node = 'root';
  }
  return fixPunctuation(expandPhrase(grammar.phrases[root_node], grammar, context));
};

exports.generate.fromPlainString = function(grammar_string, context) {
  var grammar;
  grammar_string = '%\n\t' + grammar_string;
  grammar = parse(grammar_string);
  return generate(grammar, context);
};
